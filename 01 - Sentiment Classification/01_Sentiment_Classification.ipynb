{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01 - Sentiment Classification",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5iruQ5VorWr",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Classification\n",
        "Prepared by Jan Christian Blaise Cruz\n",
        "\n",
        "In this notebook we'll see how to use PyTorch to build LSTM-based sentiment classifiers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSNmxfve9kh3",
        "colab_type": "text"
      },
      "source": [
        "# Preliminaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcZbHZG9sERT",
        "colab_type": "text"
      },
      "source": [
        "First, we'll download the necessary files and datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAOf9ocUFrhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlCaoqfJo5zz",
        "colab_type": "text"
      },
      "source": [
        "We'll import out libraries and set the necessary random seeds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG84CQ0ZFwDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "torch.manual_seed(42);\n",
        "torch.cuda.manual_seed(42);\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB3dO2aBp1sy",
        "colab_type": "text"
      },
      "source": [
        "Let's load the dataset, shuffle it, and separate it into training and validation splits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2LXHdUnFzr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('train_40.csv').sample(frac=1, random_state=42)\n",
        "text, sentiment = list(df['text']), list(df['sentiment'])\n",
        "\n",
        "tr_sz = int(len(text) * 0.7)\n",
        "\n",
        "X_train, y_train = text[:tr_sz], sentiment[:tr_sz]\n",
        "X_val, y_val = text[tr_sz:], sentiment[tr_sz:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaYfnP45qNFM",
        "colab_type": "text"
      },
      "source": [
        "Let's see how much we have in each split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoH62SbTHuW0",
        "colab_type": "code",
        "outputId": "2b4f59af-bf4f-4be9-b3d0-312d9d4a0b73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Training Set: {}\\nValidation Set: {}\".format(len(X_train), len(X_val)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set: 7000\n",
            "Validation Set: 3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3eKRXafqP3y",
        "colab_type": "text"
      },
      "source": [
        "# Text Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP6J1talqSXS",
        "colab_type": "text"
      },
      "source": [
        "First order of business is to tokenize our dataset. Tokenization refers to splitting a sequence of text into a sequence of **tokens**. There are many different ways to turn words to tokens, but space-splitting is the most common form.\n",
        "\n",
        "Let's use the ```nltk``` package to tokenize our sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLOlb3DrEjfL",
        "colab_type": "code",
        "outputId": "4ad6ad55-781e-4563-c232-2a68b5b728d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download the punkt tokenizer\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6Kux6x2qkqd",
        "colab_type": "text"
      },
      "source": [
        "We'll define a helper function to tokenize a certain sentence ```t```. The ```nltk``` package changes quotes to ``` `` ``` and ```''``` respectively because this is how the PennTreebank tokenizes quotations, so we'll have to change those back."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37XPHh6qFwSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(t):\n",
        "  return [token.replace('``', '\"').replace(\"''\", '\"') for token in word_tokenize(t)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OiTUJkoq5Fd",
        "colab_type": "text"
      },
      "source": [
        "Let's tokenize our sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwpsSoXrF5-r",
        "colab_type": "code",
        "outputId": "5bc979ca-7805-4f51-ff62-6b980ae1e6f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train = [tokenize(t) for t in tqdm(X_train)]\n",
        "X_val = [tokenize(t) for t in tqdm(X_val)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7000/7000 [00:14<00:00, 477.29it/s]\n",
            "100%|██████████| 3000/3000 [00:06<00:00, 472.97it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krfINtBsq7O8",
        "colab_type": "text"
      },
      "source": [
        "And check the first item in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIN7s5NNGTvJ",
        "colab_type": "code",
        "outputId": "15145bd5-4dd2-47ad-e7b9-b8421d3d2e8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train[0][:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', \"'m\", 'a', 'huge', 'fan']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StqYSvVjq9Lr",
        "colab_type": "text"
      },
      "source": [
        "Next thing to do is build our vocabulary. We'll define an ```idx2word``` lookup table for quick lookups (and a ```word2idx``` later on for the opposite lookup). We define a set ```vocab_set``` for quick membership checking."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t8OKKnHHBAs",
        "colab_type": "code",
        "outputId": "2216600d-fc7b-4ba5-9aa6-4842dc17c6f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "idx2word = {0: '<unk>', 1: '<pad>'}\n",
        "vocab_set = set(idx2word.values())\n",
        "\n",
        "# Add the word to the vocabulary if it's not in the vocab set\n",
        "for text in tqdm(X_train):\n",
        "  for word in text:\n",
        "    if word not in vocab_set:\n",
        "      idx2word[len(vocab_set)] = word\n",
        "      vocab_set.add(word)\n",
        "  \n",
        "# Reverse the idx2word dictionary\n",
        "word2idx = {idx2word[ix]: ix for ix in range(len(vocab_set))}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7000/7000 [00:00<00:00, 21154.92it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07JIvDr1rRd0",
        "colab_type": "text"
      },
      "source": [
        "Let's check how many tokens we have in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLdW9tpCM9-a",
        "colab_type": "code",
        "outputId": "f7d64d5d-2505-4bf5-94d9-b8e3ca8652a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(vocab_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63885"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8Fk4YscrUBh",
        "colab_type": "text"
      },
      "source": [
        "Next, we'll have the convert the tokens into their vocabulary indices (as networks cannot take raw words/tokens). We'll also have to set a maximum sequence length (msl). If a sentence is too long, we cut it, otherwise we pad it.\n",
        "\n",
        "We'll write another helper function for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0kwD0-0Jui0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize(text, word2idx, vocab_set, msl):\n",
        "  v_text = [word2idx[word] if word in vocab_set else word2idx['<unk>'] for word in text]\n",
        "  \n",
        "  # Truncate to MSL\n",
        "  v_text = v_text[:msl]\n",
        "  \n",
        "  # If shorter than MSL, pad the sequence\n",
        "  if len(v_text) < msl:\n",
        "    v_text = v_text + [word2idx['<pad>'] for _ in range(msl - len(v_text))]\n",
        "  \n",
        "  return v_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3KQxtlFri6r",
        "colab_type": "text"
      },
      "source": [
        "Let's set the maximum sequence length to 128 and process the training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwHJjqbmKMLT",
        "colab_type": "code",
        "outputId": "6c6041b1-eaad-46a1-9dfb-233ddd2dfb7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "msl = 128\n",
        "\n",
        "X_train =  [vectorize(text, word2idx, vocab_set, msl) for text in tqdm(X_train)]\n",
        "X_val =  [vectorize(text, word2idx, vocab_set, msl) for text in tqdm(X_val)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7000/7000 [00:00<00:00, 14004.35it/s]\n",
            "100%|██████████| 3000/3000 [00:00<00:00, 14056.43it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PwplrhWroCP",
        "colab_type": "text"
      },
      "source": [
        "Let's check the first item again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXEbUYMuKiX2",
        "colab_type": "code",
        "outputId": "e9557e5c-5b30-407f-b58b-6619a4588082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train[0][:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 4, 5, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMHt-jNjrqJr",
        "colab_type": "text"
      },
      "source": [
        "We now convert the lists of lists into a tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUBgJ62XKmRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = torch.LongTensor(X_train)\n",
        "X_val = torch.LongTensor(X_val)\n",
        "\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_val = torch.LongTensor(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jMfSKqQrut4",
        "colab_type": "text"
      },
      "source": [
        "Let's check their shapes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa8nqFjJNmfZ",
        "colab_type": "code",
        "outputId": "97558fb6-2d7c-462c-fc99-c95f1c7152b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"{}\\n{}\\n{}\\n{}\".format(X_train.shape, y_train.shape, X_val.shape, y_val.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([7000, 128])\n",
            "torch.Size([7000])\n",
            "torch.Size([3000, 128])\n",
            "torch.Size([3000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exmJWOE3rwHL",
        "colab_type": "text"
      },
      "source": [
        "And build the minibatches using dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6sJQdrNNwRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = 32\n",
        "\n",
        "train_set = data_utils.TensorDataset(X_train, y_train)\n",
        "val_set = data_utils.TensorDataset(X_val, y_val)\n",
        "\n",
        "train_loader = data_utils.DataLoader(train_set, bs)\n",
        "val_loader = data_utils.DataLoader(val_set, bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kETdDVmOr0Ls",
        "colab_type": "text"
      },
      "source": [
        "We can check the number of batches available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_VfI39KOKY1",
        "colab_type": "code",
        "outputId": "0bdb1c41-1a18-417c-c5a6-06e843c26aea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Number of training batches: {}\".format(len(train_loader)))\n",
        "print(\"Number of validation batches: {}\".format(len(val_loader)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training batches: 219\n",
            "Number of validation batches: 94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YomxkPC6r10Z",
        "colab_type": "text"
      },
      "source": [
        "Let's inspect the batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHkcuRRxO16J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batches = [b for b in train_loader]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-R68mCDr3Wd",
        "colab_type": "text"
      },
      "source": [
        "Here's the first batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyM6iLZlPQQq",
        "colab_type": "code",
        "outputId": "76fb4533-413c-4e83-9d0f-b08dce8ae800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x, y = batches[0]\n",
        "x.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 128]), torch.Size([32]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI8rIDLMr6Ow",
        "colab_type": "text"
      },
      "source": [
        "We can check the information inside the data and the targets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVYCDPSvPR8H",
        "colab_type": "code",
        "outputId": "36500209-18c1-4da6-f0a7-2a4131b9f163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "x, y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[   2,    3,    4,  ...,   78,   84,   19],\n",
              "         [ 164,  165,  166,  ...,  231,  232,  233],\n",
              "         [ 150,   43,  379,  ...,    1,    1,    1],\n",
              "         ...,\n",
              "         [   2,  250,  114,  ...,  579,  433, 2083],\n",
              "         [  91, 2414,   91,  ...,    7, 2446,   23],\n",
              "         [  98,  156, 2454,  ...,   23,    1,    1]]),\n",
              " tensor([1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
              "         0, 1, 0, 1, 1, 1, 0, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfey9Cprr85m",
        "colab_type": "text"
      },
      "source": [
        "Likewise, we can check the last batch and see that it has less than 32 items."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQSVowxzPVf7",
        "colab_type": "code",
        "outputId": "bc7d081d-7bbb-42f7-bd03-2ef46ea5cd39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x, y = batches[-1]\n",
        "x.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([24, 128]), torch.Size([24]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oBcfDAxPo40",
        "colab_type": "text"
      },
      "source": [
        "# Basic Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuTzoMMKySb2",
        "colab_type": "text"
      },
      "source": [
        "Next, we'll build a sentiment classifier. We'll first implement a basic Long Short-Term Memory (LSTM) Network (Hochreiter & Schmidhuber, 1997) for this. \n",
        "\n",
        "First things first, we'll look at how embeddings work in PyTorch. We can construct an embedding lookup layer using the ```nn.Embedding``` interface, supplying the size of ouur vocabulary and the dimensions of the emeddings we want.\n",
        "\n",
        "For this example, we'll use 100-dimensional embeddings. Each token $x$ will be represented by a vector $v \\in E^{100}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y23L6kqkPYa9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_sz = len(vocab_set)\n",
        "emb_dim = 100\n",
        "\n",
        "embeddings = nn.Embedding(vocab_sz, emb_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RRmaS7AziJ_",
        "colab_type": "text"
      },
      "source": [
        "Since PyTorch is eager by default, we can check how the embeddings look and behave. Let's get the first batch.\n",
        "\n",
        "Note that ```x``` is a tensor of shape $[bs , msl]$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFqCzn0WQFc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = batches[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ews0dqpKz7ve",
        "colab_type": "text"
      },
      "source": [
        "Let's pass it through the embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbh6RXfAQKPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = embeddings(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib6MpHWkz9wa",
        "colab_type": "text"
      },
      "source": [
        "And check the shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yRjDsFNQLOD",
        "colab_type": "code",
        "outputId": "9c0ec9d0-e566-4219-f80f-1a77886ef572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "out.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 128, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUBNAz6mz_Kj",
        "colab_type": "text"
      },
      "source": [
        "We've now added a third dimension as each token in each sentence has been expended to a size-100 vector.\n",
        "\n",
        "We can check the first item in the batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIQMeEDQQM9T",
        "colab_type": "code",
        "outputId": "7ec9c07e-aded-401f-f046-32fc1856052c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "out[0].shape, out[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([128, 100]),\n",
              " tensor([[-0.5208, -0.9320,  0.1852,  ...,  0.7122, -0.0318,  0.1016],\n",
              "         [ 1.3433,  0.7133,  0.3463,  ...,  0.8244,  1.4862, -1.4091],\n",
              "         [-0.7602, -0.4075,  0.9624,  ...,  0.0950, -0.7526, -0.6472],\n",
              "         ...,\n",
              "         [ 0.1549, -0.2794,  0.8709,  ...,  0.8653,  0.4257, -0.2335],\n",
              "         [-0.7383, -0.7052,  0.4542,  ..., -1.1416, -1.5392, -1.1881],\n",
              "         [ 1.0186, -0.1513, -0.9719,  ...,  0.4532,  1.1673,  0.7931]],\n",
              "        grad_fn=<SelectBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElWzKsha0LOb",
        "colab_type": "text"
      },
      "source": [
        "We can see the shape $[msl, emb\\_dim]$ as each token in the 128-length sequence is assigned a 100-dimension vector to represent it. These embeddings will be trained with the network as we go.\n",
        "\n",
        "We're now ready to pass on the data to an LSTM layer. PyTorch provides an ```nn.LSTM``` interface, passing in the embedding dimensions and our desired number of hidden units for the recurrent layer.\n",
        "\n",
        "You may type in ```nn.LSTM?``` to check inline documentation for the module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BDo_g7ra-vI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_dim = 128\n",
        "\n",
        "rnn = nn.LSTM(emb_dim, hidden_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "demFYbZf0twG",
        "colab_type": "text"
      },
      "source": [
        "Next, we'll have to instantiate the initial hidden and cell states, both of which should contain zeros. They're of shape $[1, bs, hidden\\_dim]$ each.\n",
        "\n",
        "The hidden state acts as a \"long term memory\" tape for the model, while the cell state acts as \"short term memory\" that the LSTM can use while calculating which information to pass on from the current timestep.\n",
        "\n",
        "For more information on how LSTMs work, refer to Section 10.10 of Deep Learning (Goodfellow, Bengio & Courville, 2016)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6VJPgAGa-1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h, c = torch.zeros(1, bs, hidden_dim), torch.zeros(1, bs, hidden_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTBjeeTQ1wiZ",
        "colab_type": "text"
      },
      "source": [
        "LSTMs in PyTorch require inputs with the shape $[msl, bs, emb\\_dim]$, but our current embedded inputs are $[bs, msl, emb\\_dim]$. We'll have to \"permute\" the inputs to reshape the dimensions. This is easily done using the ```.permute()``` function.\n",
        "\n",
        "We can then pass in the data and the initial hidden and cell states, then get our outputs, as well as the updated hidden and cell states."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMuNdCmha-49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = out.permute(1, 0, 2)\n",
        "\n",
        "out, (h, c) = rnn(out, (h, c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6N_Y5oC2FlS",
        "colab_type": "text"
      },
      "source": [
        "We can check the shapes of these tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu8WxVXPa-8Q",
        "colab_type": "code",
        "outputId": "1560c27d-e724-43d5-fb4e-f91e8c4d63cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "out.shape, h.shape, c.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([128, 32, 128]),\n",
              " torch.Size([1, 32, 128]),\n",
              " torch.Size([1, 32, 128]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FASoqJV2Igy",
        "colab_type": "text"
      },
      "source": [
        "These \"encoded features\" can then be used in any way we like. In this case, we want to pass it on to a softmax layer to compute probabilities (since we're classifying).\n",
        "\n",
        "We'll instantiate a linear transform layer, passing on the number of hidden units used by the LSTM, as well as the number of output units, which is 2 since we have 2 labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYkBUEtLa-_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_dim = 2\n",
        "\n",
        "fc1 = nn.Linear(hidden_dim, output_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNtxMqxz2fLt",
        "colab_type": "text"
      },
      "source": [
        "Now, which among the output, the hidden, and the cell states are we to pass on?\n",
        "\n",
        "Well, in this case we're mostly concerned with the hidden state since it contains the encoded information for all the timesteps in the sequence. We'll want to take the *last hidden state* which contains all the information.\n",
        "\n",
        "We do it, simply by indexing. Then we can pass it on to our linear layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhGOHj3Da_Ci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = h[-1, :, :]\n",
        "\n",
        "out = fc1(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwYdc_ZZ21sG",
        "colab_type": "text"
      },
      "source": [
        "We can check the shape of the output and verify that it is of shape $[bs, out\\_dim]$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qAJTE12cAHN",
        "colab_type": "code",
        "outputId": "ac6e98e3-a2f4-41d0-a016-ba1e4aba94db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "out.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_38zrZHR26dZ",
        "colab_type": "text"
      },
      "source": [
        "We can then apply softmax to it, or any other activation for that matter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BOTw4b9cAKM",
        "colab_type": "code",
        "outputId": "01b1db95-8964-46b4-9b83-ad7f41dac445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "torch.softmax(out, dim=-1)[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5328, 0.4672],\n",
              "        [0.5253, 0.4747],\n",
              "        [0.5448, 0.4552],\n",
              "        [0.4985, 0.5015],\n",
              "        [0.4885, 0.5115]], grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8KsednE29iq",
        "colab_type": "text"
      },
      "source": [
        "Putting it all together into an ```nn.Module```, we get our final model.\n",
        "\n",
        "We'll also add in a ```nn.Dropout``` layer to regularize our network a bit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfHZ-eAIcAiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "  def __init__(self, vocab_sz, emb_dim, hidden_dim, out_dim, dropout=0.5):\n",
        "    super(LSTMClassifier, self).__init__()\n",
        "    self.embeddings = nn.Embedding(vocab_sz, emb_dim)\n",
        "    self.rnn = nn.LSTM(emb_dim, hidden_dim)\n",
        "    self.fc1 = nn.Linear(hidden_dim, out_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "  def init_hidden(self, bs):\n",
        "    h, c = torch.zeros(1, bs, self.rnn.hidden_size), torch.zeros(1, bs, self.rnn.hidden_size)\n",
        "    \n",
        "    # The following line simply checks if the weights are in the GPU.\n",
        "    # If they are, put the hidden and cell states in GPU as well.\n",
        "    if next(model.parameters()).is_cuda:\n",
        "      h = h.to(device)\n",
        "      c = c.to(device)\n",
        "    return h, c\n",
        "    \n",
        "  def forward(self, x):\n",
        "    bs, msl = x.shape\n",
        "    h, c = self.init_hidden(bs)\n",
        "    \n",
        "    out = self.embeddings(x).permute(1, 0, 2)\n",
        "    out, (h, c) = self.rnn(out, (h, c))\n",
        "    out = h[-1, :, :]\n",
        "    out = self.dropout(out)\n",
        "    \n",
        "    out = self.fc1(out)\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edLcBx3g3jCU",
        "colab_type": "text"
      },
      "source": [
        "We can instantiate an instance of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igHP3HxDczSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTMClassifier(vocab_sz=len(vocab_set), emb_dim=100, hidden_dim=128, out_dim=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_QReR5l3lSH",
        "colab_type": "text"
      },
      "source": [
        "And check it's architecture quickly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyU77uJrfgUT",
        "colab_type": "code",
        "outputId": "b7da7655-42d9-44b9-c662-e285428a96a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMClassifier(\n",
              "  (embeddings): Embedding(63885, 100)\n",
              "  (rnn): LSTM(100, 128)\n",
              "  (fc1): Linear(in_features=128, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7G_pDln3nJk",
        "colab_type": "text"
      },
      "source": [
        "Let's test it out by taking a batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdQA2xXtVL7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = batches[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WfvaiS83xo3",
        "colab_type": "text"
      },
      "source": [
        "And passing it on to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-TGd-p4TnTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD2qs_493zZM",
        "colab_type": "text"
      },
      "source": [
        "And we get the expected shapes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJFGQF_AU0ON",
        "colab_type": "code",
        "outputId": "66a19ead-cd58-4721-9b01-418c8fa6a221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(out.shape)\n",
        "print(out[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 2])\n",
            "tensor([[-0.2072,  0.0464],\n",
            "        [-0.0998,  0.1200],\n",
            "        [-0.0274,  0.1417],\n",
            "        [ 0.0304,  0.0217],\n",
            "        [ 0.0453,  0.2848]], grad_fn=<SliceBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9n02fWh32Gy",
        "colab_type": "text"
      },
      "source": [
        "We can then compute a loss. We'll use cross entropy as our criterion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o_27qyeU06e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WDnSvWk353o",
        "colab_type": "text"
      },
      "source": [
        "Taking the loss is simple."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlHDLYmMVGDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = criterion(out, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbB4_jAL38ou",
        "colab_type": "text"
      },
      "source": [
        "And we can see the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjgckFgkVHZ2",
        "colab_type": "code",
        "outputId": "22990a0c-acb0-45a4-a9ac-e44896cebd67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6813, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrnxI0wy39wr",
        "colab_type": "text"
      },
      "source": [
        "Likewise we can compute for accuracy.\n",
        "\n",
        "How this function works: ```torch.exp()``` undos the natural log on the softmax, then ```torch.max(dim=1)``` finds the max on the first dimension. This function gives two outputs, the second one is the index of the max values (either 0 and 1) and that's what we want. We compare with our target $y$, take the value, then compute the percentage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayIMQeYyV13y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(out, y):\n",
        "  return torch.sum(torch.max(torch.exp(out), dim=1)[1] == y).item() / len(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFQKg8nt4g9s",
        "colab_type": "text"
      },
      "source": [
        "And we get our accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc0LerETV161",
        "colab_type": "code",
        "outputId": "20c7dd05-f35c-439e-b752-18c9007e881e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy(out, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owCRbuntVm4i",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfh4zRqA4kNH",
        "colab_type": "text"
      },
      "source": [
        "We can instantiate our model and optimizers for training. We'll use Adam (Kingma & Ba, 2014) for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tdwJpzJVPyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTMClassifier(vocab_sz=len(vocab_set), emb_dim=100, hidden_dim=128, out_dim=2, dropout=0.5).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVXsNI5c4pnd",
        "colab_type": "text"
      },
      "source": [
        "We'll train for 10 epochs. We'll also keep track of the losses so we can graph them later.\n",
        "\n",
        "For this example, we'll also employ some gradient clipping to prevent the gradients from exploding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSO3k0huVuTf",
        "colab_type": "code",
        "outputId": "ee0278ed-9c19-4187-91f9-fb54bd09ae00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "epochs = 10\n",
        "clip = 0.25\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for e in range(1, epochs + 1):\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "\n",
        "  model.train()\n",
        "  for batch in tqdm(train_loader):\n",
        "    x, y = batch\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    out = model(x)\n",
        "    loss = criterion(out, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "    train_acc += accuracy(out, y)\n",
        "\n",
        "  train_loss /= len(train_loader)\n",
        "  train_acc /= len(train_loader)\n",
        "  \n",
        "  train_losses.append(train_loss)\n",
        "\n",
        "  val_loss = 0\n",
        "  val_acc = 0\n",
        "\n",
        "  model.eval()\n",
        "  for batch in tqdm(val_loader):\n",
        "    with torch.no_grad():\n",
        "      x, y = batch\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      out = model(x)\n",
        "      loss = criterion(out, y)\n",
        "\n",
        "      val_loss += loss.item()\n",
        "      val_acc += accuracy(out, y)\n",
        "\n",
        "  val_loss /= len(val_loader)\n",
        "  val_acc /= len(val_loader)\n",
        "  \n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  print(\"\\nEpoch {:3} | Train Loss: {:.4f} | Train Acc: {:.4f} | Val Loss: {:.4f} | Val Acc: {:.4f}\".format(e, train_loss, train_acc, val_loss, val_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:06<00:00, 33.13it/s]\n",
            "100%|██████████| 94/94 [00:00<00:00, 142.76it/s]\n",
            "  2%|▏         | 4/219 [00:00<00:05, 36.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch   1 | Train Loss: 0.6951 | Train Acc: 0.5073 | Val Loss: 0.6924 | Val Acc: 0.5171\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:06<00:00, 35.10it/s]\n",
            "100%|██████████| 94/94 [00:00<00:00, 146.39it/s]\n",
            "  2%|▏         | 4/219 [00:00<00:06, 35.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch   2 | Train Loss: 0.6928 | Train Acc: 0.5223 | Val Loss: 0.6916 | Val Acc: 0.5228\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:06<00:00, 35.09it/s]\n",
            "100%|██████████| 94/94 [00:00<00:00, 141.02it/s]\n",
            "  2%|▏         | 4/219 [00:00<00:05, 36.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch   3 | Train Loss: 0.6912 | Train Acc: 0.5300 | Val Loss: 0.6913 | Val Acc: 0.5227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:06<00:00, 34.75it/s]\n",
            "100%|██████████| 94/94 [00:00<00:00, 140.00it/s]\n",
            "  2%|▏         | 4/219 [00:00<00:05, 37.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch   4 | Train Loss: 0.6897 | Train Acc: 0.5369 | Val Loss: 0.6909 | Val Acc: 0.5301\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:06<00:00, 35.45it/s]\n",
            "100%|██████████| 94/94 [00:00<00:00, 142.05it/s]\n",
            "  2%|▏         | 4/219 [00:00<00:05, 36.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch   5 | Train Loss: 0.6876 | Train Acc: 0.5446 | Val Loss: 0.6904 | Val Acc: 0.5275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:06<00:00, 35.36it/s]\n",
            "100%|██████████| 94/94 [00:00<00:00, 143.75it/s]\n",
            "  2%|▏         | 4/219 [00:00<00:05, 36.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch   6 | Train Loss: 0.6844 | Train Acc: 0.5609 | Val Loss: 0.6900 | Val Acc: 0.5265\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:06<00:00, 35.34it/s]\n",
            "100%|██████████| 94/94 [00:00<00:00, 136.25it/s]\n",
            "  2%|▏         | 4/219 [00:00<00:05, 36.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch   7 | Train Loss: 0.6821 | Train Acc: 0.5713 | Val Loss: 0.6896 | Val Acc: 0.5320\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:06<00:00, 35.05it/s]\n",
            "100%|██████████| 94/94 [00:00<00:00, 140.99it/s]\n",
            "  2%|▏         | 4/219 [00:00<00:05, 36.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch   8 | Train Loss: 0.6783 | Train Acc: 0.5806 | Val Loss: 0.6884 | Val Acc: 0.5382\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:06<00:00, 35.37it/s]\n",
            "100%|██████████| 94/94 [00:00<00:00, 145.42it/s]\n",
            "  2%|▏         | 4/219 [00:00<00:06, 35.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch   9 | Train Loss: 0.6712 | Train Acc: 0.5946 | Val Loss: 0.6831 | Val Acc: 0.5603\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:06<00:00, 34.85it/s]\n",
            "100%|██████████| 94/94 [00:00<00:00, 142.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  10 | Train Loss: 0.6476 | Train Acc: 0.6238 | Val Loss: 0.6394 | Val Acc: 0.6437\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPCYaZg345_-",
        "colab_type": "text"
      },
      "source": [
        "We can then plot our loss curves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXIXpKObXDRp",
        "colab_type": "code",
        "outputId": "3f6090d0-91e8-4796-d097-ac2c5ae6841c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "pd.DataFrame(data={'train_loss': train_losses, 'val_loss': val_losses}).plot.line()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faee8dd5828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nG2PMAPJ/AeGrYkdXZQ3sAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqQckUaHmlE7",
        "colab_type": "text"
      },
      "source": [
        "# Bidirectional + Stacked LSTMs and Pretrained Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdAJ9H1o49_w",
        "colab_type": "text"
      },
      "source": [
        "In this segment, we'll add more capacity to our basic LSTM network by introducing bidirectionality, stacking more LSTMs, and using pretrained embeddings.\n",
        "\n",
        "Likewise, let's take a batch first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLKMow9OYdre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = batches[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "220cKLh05MQI",
        "colab_type": "text"
      },
      "source": [
        "Let's build our embedding and LSTM layers. We see some new stuff in here.\n",
        "\n",
        "You can specify the number of stacked LSTMs you want (default is 1). Bidirectionality is a boolean you can pass on. We can also introduce dropout between each LSTM layer if the number of layers is > 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq78XqpjmsGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_sz = len(vocab_set)\n",
        "emb_dim = 100\n",
        "hidden_dim = 128\n",
        "out_dim = 2\n",
        "num_layers = 2\n",
        "bidirectional = True\n",
        "recur_dropout = 0.3\n",
        "\n",
        "embeddings = nn.Embedding(vocab_sz, emb_dim)\n",
        "rnn = nn.LSTM(emb_dim, hidden_dim, bidirectional=bidirectional, \n",
        "              num_layers=num_layers, dropout=recur_dropout)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc-OigAH5cnJ",
        "colab_type": "text"
      },
      "source": [
        "One of the two things that changes is the shape of the hidden and cell states.\n",
        "\n",
        "Earlier, we simply have states of shape $[1, bs, hidden\\_dim]$.\n",
        "\n",
        "When stacking LSTM layers, each layer gets its own hidden and cell state tensors. A two-layer stacked LSTM thus has states of shape $[2, bs, hidden\\_dim]$.\n",
        "\n",
        "If the network is bidirectional, each layer gets **two** hidden and cell states, one for the forward pass, and the other for the backward pass. A two-layer bidirectional LSTM thus has states of shape $[4, bs, hidden\\_dim]$, and a three layer bidirectional one has $[6, bs, hidden\\_dim]$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVI5HaMem6iw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "direction = 2 if bidirectional else 1\n",
        "\n",
        "h, c = torch.zeros(direction * num_layers, bs, hidden_dim), torch.zeros(direction * num_layers, bs, hidden_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxP8xr5n6XxM",
        "colab_type": "text"
      },
      "source": [
        "We check the shapes of our states."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL4e46-ZnKE5",
        "colab_type": "code",
        "outputId": "f3af7650-fd80-44b7-f4b2-87b84d284ae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "h.shape, c.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 32, 128]), torch.Size([4, 32, 128]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKR0duBP6ZgK",
        "colab_type": "text"
      },
      "source": [
        "And passing it on remains the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr0vTv6YnM0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = embeddings(x).permute(1, 0, 2)\n",
        "out, (h, c) = rnn(out, (h, c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ION0RBKX6bVj",
        "colab_type": "text"
      },
      "source": [
        "We can check the shapes of the outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmFNWrOwnTVt",
        "colab_type": "code",
        "outputId": "4a78a7ab-c98d-4642-a7fa-e01e749c5a18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "out.shape, h.shape, c.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([128, 32, 256]),\n",
              " torch.Size([4, 32, 128]),\n",
              " torch.Size([4, 32, 128]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gARcFYyT6djJ",
        "colab_type": "text"
      },
      "source": [
        "**If the network is bidirectional**, indexing the hidden state changes. We take the last two tensors and concatenate them along the first dimension. This represents the last forward and last backward hidden states, which contains all the encoded information. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxV-kds0nUbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = torch.cat( (h[-1, :, :], h[-2, :, :]) , dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK1gipqx6-ht",
        "colab_type": "text"
      },
      "source": [
        "This operation results in a tensor of shape $[bs, hidden\\_dim * 2]$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGKjH4YtnauN",
        "colab_type": "code",
        "outputId": "35d670a2-1e4e-4106-fbf9-cd8bdb4d1ef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "out.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IMLqgI47E1N",
        "colab_type": "text"
      },
      "source": [
        "So if the network is bidirectional, the next layer should also have twice the number of input dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU52zajWnpY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fc1 = nn.Linear(hidden_dim * 2, out_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prt7XztR7JmI",
        "colab_type": "text"
      },
      "source": [
        "Everything else remains the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YUlC9q6nsKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = fc1(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rqd-rRt7MC7",
        "colab_type": "text"
      },
      "source": [
        "We can check the sizes of the tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YK3S4xfnvMC",
        "colab_type": "code",
        "outputId": "44ebabcd-0c00-4515-b635-f80d39ac345b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(out.shape)\n",
        "print(out[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 2])\n",
            "tensor([[ 0.0130,  0.0247],\n",
            "        [-0.0189, -0.0212],\n",
            "        [-0.0286, -0.0009],\n",
            "        [-0.0332,  0.0102],\n",
            "        [-0.0160,  0.0012]], grad_fn=<SliceBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBOxkzVv7Og0",
        "colab_type": "text"
      },
      "source": [
        "And put everything together into an updated ```LSTMClassifier``` module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO1fb51onxGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "  def __init__(self, vocab_sz, emb_dim, hidden_dim, out_dim, bidirectional=False, num_layers=1, dropout=0.5, emb_dropout=0.1, recur_dropout=0.3):\n",
        "    super(LSTMClassifier, self).__init__()\n",
        "    self.embeddings = nn.Embedding(vocab_sz, emb_dim)\n",
        "    self.rnn = nn.LSTM(emb_dim, hidden_dim, bidirectional=bidirectional, num_layers=num_layers, dropout=recur_dropout)\n",
        "    self.fc1 = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, out_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "    \n",
        "  def init_hidden(self, bs):\n",
        "    direction = 2 if self.rnn.bidirectional else 1\n",
        "    num_layers = self.rnn.num_layers\n",
        "    h, c = torch.zeros(direction * num_layers, bs, self.rnn.hidden_size), torch.zeros(direction * num_layers, bs, self.rnn.hidden_size)\n",
        "    \n",
        "    if next(model.parameters()).is_cuda:\n",
        "      h = h.to(device)\n",
        "      c = c.to(device)\n",
        "    return h, c\n",
        "    \n",
        "  def forward(self, x):\n",
        "    bs, msl = x.shape\n",
        "    h, c = self.init_hidden(bs)\n",
        "    \n",
        "    out = self.embeddings(x).permute(1, 0, 2)\n",
        "    out = self.emb_dropout(out)\n",
        "    out, (h, c) = self.rnn(out, (h, c))\n",
        "    \n",
        "    if self.rnn.bidirectional:\n",
        "      out = torch.cat( (h[-1, :, :], h[-2, :, :]) , dim=1)\n",
        "    else:\n",
        "      out = h[-1, :, :]\n",
        "      \n",
        "    out = self.dropout(out)\n",
        "    out = self.fc1(out)\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13jCg4wh7ZlR",
        "colab_type": "text"
      },
      "source": [
        "Let's instantiate our model and optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9FPRjYfp-Ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTMClassifier(vocab_sz=len(vocab_set), emb_dim=100, hidden_dim=128, out_dim=2, dropout=0.5, bidirectional=True, num_layers=2).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL0lMK_B7cTY",
        "colab_type": "text"
      },
      "source": [
        "But before we train it, let's use pretrained embeddings instead of training our own.\n",
        "\n",
        "Pretrained embeddings have been standard benchmarks since they provide the network with richer feature representations. For detailed information on how these embeddings are trained, please see Mikolov et al. (2013), Pennington et al. (2014), and Joulin et al. (2017).\n",
        "\n",
        "For this example, we'll use the 100-dimension GloVe (Pennington et al., 2014) pretrained embeddings from Stanford NLP's repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Wr3KkLPzljw",
        "colab_type": "code",
        "outputId": "0362146c-c8d5-4c06-a55f-fe82a2d2c1c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('glove.6B.100d.txt', 'r') as f:\n",
        "  lines = [l.strip() for l in f]\n",
        "  \n",
        "# Produce a vocabulary list and a lookup table\n",
        "emb_vocab = []\n",
        "word2emb = {}\n",
        "for l in tqdm(lines):\n",
        "  l = l.split()\n",
        "  emb_vocab.append(l[0])\n",
        "  word2emb[l[0]] = [float(f) for f in l[1:]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 400000/400000 [00:15<00:00, 25123.16it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cznfzSrI8Rcf",
        "colab_type": "text"
      },
      "source": [
        "We can check the first item in the embedding vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxmWigsZznBK",
        "colab_type": "code",
        "outputId": "214df2ae-ab48-485f-cc09-631d5047218c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "emb_vocab[0], word2emb[emb_vocab[0]][:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('the', [-0.038194, -0.24487, 0.72812, -0.39961, 0.083172])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y333njd8VDF",
        "colab_type": "text"
      },
      "source": [
        "For every word in our own vocabulary, if a corresponding entry appears in the pretrained embeddings, we take those embeddings, otherwise we take a zero-tensor instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PW1sQgCzupr",
        "colab_type": "code",
        "outputId": "59f6b6e3-03f9-49f8-9416-a2641eb7317b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Produce a set for O(1) lookups\n",
        "emb_vocab_set = set(emb_vocab)\n",
        "emb_dim = 100\n",
        "\n",
        "# Copy matching embeddings IN ORDER\n",
        "copied_weights = []\n",
        "for word in tqdm(word2idx.keys()):\n",
        "  if word in emb_vocab_set:\n",
        "    copied_weights.append(word2emb[word])\n",
        "  else:\n",
        "    copied_weights.append([0 for _ in range(emb_dim)])\n",
        "    \n",
        "# Transform the copied embedding weights into a tensor\n",
        "copied_weights = torch.stack([torch.FloatTensor(weight) for weight in copied_weights])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 63885/63885 [00:00<00:00, 187453.99it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vpg1H-Dw8pjX",
        "colab_type": "text"
      },
      "source": [
        "We can check the shape of our copied weights and confirm they're of shape $[vocab\\_sz, emb\\_dim]$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rzXuaH5zxdC",
        "colab_type": "code",
        "outputId": "e4916823-e4e1-4182-a054-c01664094ee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "copied_weights.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([63885, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US_l_Lcr80t5",
        "colab_type": "text"
      },
      "source": [
        "We will then copy these weights into the embedding layer of our model, then **freeze** them so the network doesn't update them. They act as feature extractors this way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L7icu5IzzAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.embeddings.weight.data.copy_(copied_weights);\n",
        "model.embeddings.weight.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey2nmEfo88al",
        "colab_type": "text"
      },
      "source": [
        "We then train with the same settings for 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtKwzVlQqCwV",
        "colab_type": "code",
        "outputId": "e45d00e0-3567-4b60-e33d-a016521f8d4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 50\n",
        "clip = 0.25\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for e in range(1, epochs + 1):\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "\n",
        "  model.train()\n",
        "  for batch in tqdm(train_loader):\n",
        "    x, y = batch\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    out = model(x)\n",
        "    loss = criterion(out, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "    train_acc += accuracy(out, y)\n",
        "\n",
        "  train_loss /= len(train_loader)\n",
        "  train_acc /= len(train_loader)\n",
        "  \n",
        "  train_losses.append(train_loss)\n",
        "\n",
        "  val_loss = 0\n",
        "  val_acc = 0\n",
        "\n",
        "  model.eval()\n",
        "  for batch in tqdm(val_loader):\n",
        "    with torch.no_grad():\n",
        "      x, y = batch\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      out = model(x)\n",
        "      loss = criterion(out, y)\n",
        "\n",
        "      val_loss += loss.item()\n",
        "      val_acc += accuracy(out, y)\n",
        "\n",
        "  val_loss /= len(val_loader)\n",
        "  val_acc /= len(val_loader)\n",
        "  \n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  print(\"\\nEpoch {:3} | Train Loss: {:.4f} | Train Acc: {:.4f} | Val Loss: {:.4f} | Val Acc: {:.4f}\".format(e, train_loss, train_acc, val_loss, val_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:24<00:00,  9.34it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 50.79it/s]\n",
            "  1%|          | 2/219 [00:00<00:19, 11.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch   1 | Train Loss: 0.6914 | Train Acc: 0.5221 | Val Loss: 0.6853 | Val Acc: 0.6021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.63it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 53.44it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch   2 | Train Loss: 0.6701 | Train Acc: 0.5973 | Val Loss: 0.6186 | Val Acc: 0.6682\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.52it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.11it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch   3 | Train Loss: 0.6263 | Train Acc: 0.6602 | Val Loss: 0.6694 | Val Acc: 0.6411\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.58it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.58it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch   4 | Train Loss: 0.6094 | Train Acc: 0.6755 | Val Loss: 0.5722 | Val Acc: 0.7113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.57it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 51.94it/s]\n",
            "  1%|          | 2/219 [00:00<00:19, 11.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch   5 | Train Loss: 0.5923 | Train Acc: 0.6958 | Val Loss: 0.5890 | Val Acc: 0.6802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.57it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 53.98it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch   6 | Train Loss: 0.5797 | Train Acc: 0.7003 | Val Loss: 0.5493 | Val Acc: 0.7281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.56it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 50.77it/s]\n",
            "  1%|          | 2/219 [00:00<00:19, 11.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch   7 | Train Loss: 0.5718 | Train Acc: 0.7090 | Val Loss: 0.5550 | Val Acc: 0.7366\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.60it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 53.63it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch   8 | Train Loss: 0.5546 | Train Acc: 0.7202 | Val Loss: 0.6173 | Val Acc: 0.6724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.51it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.09it/s]\n",
            "  1%|          | 2/219 [00:00<00:19, 11.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch   9 | Train Loss: 0.5475 | Train Acc: 0.7323 | Val Loss: 0.5600 | Val Acc: 0.7092\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.51it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 51.57it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  10 | Train Loss: 0.5363 | Train Acc: 0.7412 | Val Loss: 0.5462 | Val Acc: 0.7312\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.57it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.42it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  11 | Train Loss: 0.5341 | Train Acc: 0.7414 | Val Loss: 0.5371 | Val Acc: 0.7325\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.43it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.82it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  12 | Train Loss: 0.5259 | Train Acc: 0.7455 | Val Loss: 0.6231 | Val Acc: 0.7040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.52it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.87it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  13 | Train Loss: 0.5289 | Train Acc: 0.7439 | Val Loss: 0.5232 | Val Acc: 0.7458\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.48it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.46it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  14 | Train Loss: 0.5157 | Train Acc: 0.7517 | Val Loss: 0.5311 | Val Acc: 0.7439\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.42it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 51.57it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  15 | Train Loss: 0.5075 | Train Acc: 0.7561 | Val Loss: 0.5000 | Val Acc: 0.7696\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.37it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 53.49it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  16 | Train Loss: 0.5153 | Train Acc: 0.7525 | Val Loss: 0.5260 | Val Acc: 0.7426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.43it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.67it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  17 | Train Loss: 0.4958 | Train Acc: 0.7678 | Val Loss: 0.5769 | Val Acc: 0.6995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.54it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 53.26it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  18 | Train Loss: 0.4970 | Train Acc: 0.7631 | Val Loss: 0.5037 | Val Acc: 0.7516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.45it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 54.35it/s]\n",
            "  1%|          | 2/219 [00:00<00:19, 11.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  19 | Train Loss: 0.5023 | Train Acc: 0.7618 | Val Loss: 0.4904 | Val Acc: 0.7777\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.48it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.09it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  20 | Train Loss: 0.4869 | Train Acc: 0.7721 | Val Loss: 0.4753 | Val Acc: 0.7758\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.50it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.33it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  21 | Train Loss: 0.4837 | Train Acc: 0.7740 | Val Loss: 0.5756 | Val Acc: 0.7047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.51it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 53.08it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  22 | Train Loss: 0.4770 | Train Acc: 0.7748 | Val Loss: 0.5053 | Val Acc: 0.7510\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.44it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.28it/s]\n",
            "  1%|          | 2/219 [00:00<00:19, 11.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  23 | Train Loss: 0.4740 | Train Acc: 0.7769 | Val Loss: 0.4680 | Val Acc: 0.7832\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.57it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.70it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  24 | Train Loss: 0.4659 | Train Acc: 0.7848 | Val Loss: 0.5044 | Val Acc: 0.7540\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.48it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 53.76it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  25 | Train Loss: 0.4614 | Train Acc: 0.7867 | Val Loss: 0.5288 | Val Acc: 0.7634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.50it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 53.05it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  26 | Train Loss: 0.4502 | Train Acc: 0.7911 | Val Loss: 0.4602 | Val Acc: 0.7879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.49it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.76it/s]\n",
            "  1%|          | 2/219 [00:00<00:19, 11.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  27 | Train Loss: 0.4480 | Train Acc: 0.7907 | Val Loss: 0.5175 | Val Acc: 0.7500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.50it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 53.01it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  28 | Train Loss: 0.4456 | Train Acc: 0.7899 | Val Loss: 0.4618 | Val Acc: 0.7969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.54it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 53.90it/s]\n",
            "  1%|          | 2/219 [00:00<00:17, 12.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  29 | Train Loss: 0.4530 | Train Acc: 0.7927 | Val Loss: 0.4904 | Val Acc: 0.7789\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.46it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 53.15it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  30 | Train Loss: 0.4419 | Train Acc: 0.7942 | Val Loss: 0.4429 | Val Acc: 0.7932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.58it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 51.31it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  31 | Train Loss: 0.4417 | Train Acc: 0.7966 | Val Loss: 0.4392 | Val Acc: 0.7969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.48it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 53.24it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  32 | Train Loss: 0.4484 | Train Acc: 0.7944 | Val Loss: 0.4816 | Val Acc: 0.7867\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.46it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 53.04it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  33 | Train Loss: 0.4367 | Train Acc: 0.7972 | Val Loss: 0.4677 | Val Acc: 0.7883\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.47it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.34it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  34 | Train Loss: 0.4320 | Train Acc: 0.8029 | Val Loss: 0.4687 | Val Acc: 0.7789\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.45it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.65it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  35 | Train Loss: 0.4307 | Train Acc: 0.8087 | Val Loss: 0.5009 | Val Acc: 0.7821\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.54it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 51.73it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  36 | Train Loss: 0.4343 | Train Acc: 0.8033 | Val Loss: 0.5059 | Val Acc: 0.7788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.40it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.43it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  37 | Train Loss: 0.4194 | Train Acc: 0.8085 | Val Loss: 0.4534 | Val Acc: 0.8013\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.55it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.26it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  38 | Train Loss: 0.4148 | Train Acc: 0.8125 | Val Loss: 0.5240 | Val Acc: 0.7656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.48it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 51.89it/s]\n",
            "  1%|          | 2/219 [00:00<00:17, 12.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  39 | Train Loss: 0.4185 | Train Acc: 0.8121 | Val Loss: 0.4962 | Val Acc: 0.7752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.53it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.68it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  40 | Train Loss: 0.4225 | Train Acc: 0.8115 | Val Loss: 0.5649 | Val Acc: 0.7501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.53it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 53.12it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  41 | Train Loss: 0.4125 | Train Acc: 0.8150 | Val Loss: 0.4820 | Val Acc: 0.7963\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.63it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.24it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  42 | Train Loss: 0.4024 | Train Acc: 0.8181 | Val Loss: 0.5029 | Val Acc: 0.7815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.37it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.32it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  43 | Train Loss: 0.3996 | Train Acc: 0.8237 | Val Loss: 0.4934 | Val Acc: 0.7900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.50it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.71it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  44 | Train Loss: 0.3953 | Train Acc: 0.8279 | Val Loss: 0.5735 | Val Acc: 0.7333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.57it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.45it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  45 | Train Loss: 0.4008 | Train Acc: 0.8204 | Val Loss: 0.5433 | Val Acc: 0.7516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.51it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.96it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  46 | Train Loss: 0.3950 | Train Acc: 0.8255 | Val Loss: 0.4648 | Val Acc: 0.7922\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.60it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.25it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  47 | Train Loss: 0.3932 | Train Acc: 0.8309 | Val Loss: 0.4742 | Val Acc: 0.7927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:19<00:00, 11.50it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 53.22it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  48 | Train Loss: 0.3784 | Train Acc: 0.8332 | Val Loss: 0.4367 | Val Acc: 0.8029\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.62it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.89it/s]\n",
            "  1%|          | 2/219 [00:00<00:18, 11.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  49 | Train Loss: 0.3752 | Train Acc: 0.8355 | Val Loss: 0.4906 | Val Acc: 0.7876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 219/219 [00:18<00:00, 11.59it/s]\n",
            "100%|██████████| 94/94 [00:01<00:00, 52.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  50 | Train Loss: 0.3908 | Train Acc: 0.8307 | Val Loss: 0.5415 | Val Acc: 0.7537\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0rt6sIj8-up",
        "colab_type": "text"
      },
      "source": [
        "And plot the losses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL1N3rEoqGmp",
        "colab_type": "code",
        "outputId": "cb0167c4-3aff-435d-ba34-0842fe3c3c78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "pd.DataFrame(data={'train_loss': train_losses, 'val_loss': val_losses}).plot.line()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faeed730668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLBeTDEcdDgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmQ4Aa-U9K1m",
        "colab_type": "text"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GazUE428_6i",
        "colab_type": "text"
      },
      "source": [
        "We can perform predictions on the model.\n",
        "\n",
        "Let's put the model back into the CPU and put it in evaluation mode to turn off dropout."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBOte3Es3GvN",
        "colab_type": "code",
        "outputId": "68468569-71fc-418c-a0c7-c82821586ba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "model.cpu()\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMClassifier(\n",
              "  (embeddings): Embedding(63885, 100)\n",
              "  (rnn): LSTM(100, 128, num_layers=2, dropout=0.3, bidirectional=True)\n",
              "  (fc1): Linear(in_features=256, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5)\n",
              "  (emb_dropout): Dropout(p=0.1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UqSUZR79GVI",
        "colab_type": "text"
      },
      "source": [
        "Let's define a prediction function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y0uoByZ3hTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(text):\n",
        "  tokens = tokenize(text)\n",
        "  vect = vectorize(tokens, word2idx, vocab_set, msl)\n",
        "  x = torch.LongTensor(vect).unsqueeze(0)\n",
        "\n",
        "  out = torch.softmax(model(x), dim=1)\n",
        "  pred = torch.max(out[0], dim=0)[1].item()\n",
        "\n",
        "  print(pred, out)\n",
        "  print(\"Positive\") if pred == 0 else print(\"Negative\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGHyLP8n9INY",
        "colab_type": "text"
      },
      "source": [
        "And cast some predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnw70BrL4glU",
        "colab_type": "code",
        "outputId": "8db2759a-601e-45b2-a96f-075972a5cf26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "predict(\"I hated that movie it was very bad\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 tensor([[0.0412, 0.9588]], grad_fn=<SoftmaxBackward>)\n",
            "Negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl18KlBW4i4G",
        "colab_type": "code",
        "outputId": "889ecc77-6dfe-4ddb-9491-19aeae7d08a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "predict(\"That was a really good movie!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor([[0.9049, 0.0951]], grad_fn=<SoftmaxBackward>)\n",
            "Positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO4ZjQfD4kyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}